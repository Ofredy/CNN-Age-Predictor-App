{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8o3OLq1yz5Zco/L34Ru7N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ofredy/CNN-Age-Predictor-App/blob/main/workshop/week3%264/cnn_cat_dog_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA9wz8stbuo1"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notebook Constants\n",
        "CAT_LABEL = 3\n",
        "DOG_LABEL = 5\n",
        "BATCH_SIZE = 32\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Loading in the CIFAR10 Dataset\n",
        "train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "val = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "ffFF-GJGcPST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the dataloaders with only cat and dog images\n",
        "cat_dog_idx = [CAT_LABEL, DOG_LABEL]\n",
        "\n",
        "indices = [idx for idx, target in enumerate(train.targets) if target in cat_dog_idx]\n",
        "train_data_loader = torch.utils.data.DataLoader(data.Subset(train, indices), shuffle=True, drop_last=True, batch_size=BATCH_SIZE)\n",
        "\n",
        "indices = [idx for idx, target in enumerate(val.targets) if target in cat_dog_idx]\n",
        "val_data_loader = torch.utils.data.DataLoader(data.Subset(val, indices), shuffle=True, drop_last=True, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "nukwMLIPcnNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our CatvsDog Classifier\n",
        "class CatDogClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, net_dim=8):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        ### Write code here ###\n",
        "\n",
        "         # Hidden Layer 1\n",
        "        self.conv1 =\n",
        "\n",
        "         # Hidden Layer 2\n",
        "        self.conv2 =\n",
        "\n",
        "         # Hidden Layer 3\n",
        "        self.conv3 =\n",
        "\n",
        "         # Hidden Layer 4\n",
        "        self.linear4 =\n",
        "\n",
        "        self.relu =\n",
        "        self.sigmoid =\n",
        "\n",
        "        #######################\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ### Write code here ###\n",
        "\n",
        "        #######################\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "z7L8wfM1dw9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to change Cat and Dog labels to 1 and 0, to allow for correct backpropagation\n",
        "def update_labels(labels):\n",
        "\n",
        "    labels = torch.unsqueeze(labels, 1)\n",
        "\n",
        "    labels[labels == CAT_LABEL] = 1.0\n",
        "    labels[labels == DOG_LABEL] = 0.0\n",
        "\n",
        "    return labels.to(torch.float32)\n",
        "\n",
        "# Training Function\n",
        "def training_loop(classifier, train_loader, val_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
        "\n",
        "    # Empty List to log the progress of the training\n",
        "    train_losses, val_losses = [], []\n",
        "    # Accuracy of the network performed only on the validation data\n",
        "    accuracy = []\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "\n",
        "        train_loss, val_loss = 0, 0\n",
        "        labels_correct = 0\n",
        "\n",
        "        # Training\n",
        "        classifier.train()\n",
        "\n",
        "        # Iterating through the training data by the batch_size\n",
        "        for imgs, labels in train_loader:\n",
        "\n",
        "            # Preprocessing the input images\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            # Preprocessing the input labels\n",
        "            labels = update_labels(labels)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            ### Write code here ###\n",
        "\n",
        "            # Forward\n",
        "            predicted_labels =\n",
        "\n",
        "            # Backward\n",
        "            cost =\n",
        "\n",
        "            #######################\n",
        "\n",
        "            train_loss += cost.item()\n",
        "\n",
        "        # Val\n",
        "        classifier.eval()\n",
        "\n",
        "        # Iterating through the validation data by the batch_size\n",
        "        for imgs, labels in val_loader:\n",
        "\n",
        "            # Preprocessing the input images\n",
        "            imgs = imgs.to(device)\n",
        "\n",
        "            # Preprocessing the input labels\n",
        "            labels = update_labels(labels)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Making our predictions\n",
        "\n",
        "                ### Write code here ###\n",
        "\n",
        "                predicted_labels =\n",
        "\n",
        "                #######################\n",
        "\n",
        "            # Calculating the accuracy and validation loss\n",
        "            labels_correct += ((predicted_labels > 0.5) == labels).float().sum()\n",
        "            cost = criterion(predicted_labels, labels)\n",
        "\n",
        "            val_loss += cost.item()\n",
        "\n",
        "        train_losses.append(train_loss/len(train_loader))\n",
        "        val_losses.append(val_loss/len(val_loader))\n",
        "        accuracy.append(labels_correct/(len(val_loader)*BATCH_SIZE))\n",
        "\n",
        "        print(\"Epoch: %d, Train Loss: %f, Val Loss: %f, Accuracy: %f\" % (epoch, train_losses[epoch-1], val_losses[epoch-1], accuracy[epoch-1]))\n",
        "\n",
        "    return classifier, train_losses, val_losses, accuracy"
      ],
      "metadata": {
        "id": "w26mR7QfiYPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the cat_dog_classifier, defining the loss function, and defining the optimizer\n",
        "cat_dog_classfier = CatDogClassifier().to('cuda')\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(cat_dog_classfier.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "jp8XmC7sorPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing training\n",
        "cat_dog_classfier, train_losses, val_losses, accuracy = training_loop(cat_dog_classfier, train_data_loader, val_data_loader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "C9u3o4c2pWFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}